{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voting_Ensamble_2_and_Stacking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCCtBVwQzFclhImcycBL6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/ACM/blob/master/Voting_Ensamble_2_and_Stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y1Z-N9LSnfQf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#data = 'https://raw.githubusercontent.com/RafsanJany-44/Machine-School/main/datasets/HMC_WITH_BIOM.csv'\n",
        "#data=\"https://raw.githubusercontent.com/RafsanJany-44/Research-NREM-REM/main/dataset/REM_NREM.csv\"\n",
        "#data=\"https://raw.githubusercontent.com/RafsanJany-44/Machine-School/main/datasets/EEG_HMC.csv\"\n",
        "data=\"https://raw.githubusercontent.com/RafsanJany-44/Machine-School/main/datasets/REM_NREM_O2.csv\"\n",
        "dataset = pd.read_csv(data)\n",
        "encoder=LabelEncoder()\n",
        "dataset[\"Sleep_Stage\"]=encoder.fit_transform(dataset[\"Sleep_Stage\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 1:].values\n",
        "y = dataset.iloc[:, 0].values\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 10)"
      ],
      "metadata": {
        "id": "Opdybyw1nlN4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        " \n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "2o-ULvTVnmwr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# create the synthetic classification dataset\n",
        "X, y = make_classification(random_state=1)\n",
        "# configure the models to use in the ensemble\n",
        "models = [('lr', LogisticRegression()), ('nb', GaussianNB())]\n",
        "# configure the ensemble model\n",
        "model = VotingClassifier(models, voting='hard')\n",
        "# configure the resampling method\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the ensemble on the dataset using the resampling method\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report ensemble performance\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waBFNSRwqkmv",
        "outputId": "c137d174-468f-416a-95e1-9cc4b9f78bcc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.957 (0.062)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of evaluating a stacking ensemble for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# create the synthetic classification dataset\n",
        "X, y = make_classification(random_state=1)\n",
        "# configure the models to use in the ensemble\n",
        "models = [('knn', KNeighborsClassifier()), ('tree', DecisionTreeClassifier())]\n",
        "# configure the ensemble model\n",
        "model = StackingClassifier(models, final_estimator=LogisticRegression(), cv=3)\n",
        "# configure the resampling method\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the ensemble on the dataset using the resampling method\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report ensemble performance\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge66MI-ur9jJ",
        "outputId": "bb040496-a656-41f3-ffd7-1f0d3db12dfb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.920 (0.101)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------"
      ],
      "metadata": {
        "id": "akj-1wUGthb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier"
      ],
      "metadata": {
        "id": "Bh1IGHlBtjCA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple avg approch"
      ],
      "metadata": {
        "id": "nWRFGWR4t2FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LogReg_clf = LogisticRegression()\n",
        "DTree_clf = DecisionTreeClassifier()\n",
        "SVC_clf = SVC()\n",
        "\n",
        "LogReg_clf.fit(X_train, y_train)\n",
        "DTree_clf.fit(X_train, y_train)\n",
        "SVC_clf.fit(X_train, y_train)\n",
        "\n",
        "LogReg_pred = LogReg_clf.predict(X_test)\n",
        "DTree_pred = DTree_clf.predict(X_test)\n",
        "SVC_pred = SVC_clf.predict(X_test)\n",
        "\n",
        "print(LogReg_pred,type(LogReg_pred))\n",
        "print(DTree_pred,type(DTree_pred))\n",
        "print(SVC_pred,type(SVC_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGLUhvT5tmat",
        "outputId": "25d38c33-e1ee-4543-fde8-b27ff771f62a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0] <class 'numpy.ndarray'>\n",
            "[1 0 1 ... 1 0 0] <class 'numpy.ndarray'>\n",
            "[0 0 0 ... 0 0 0] <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf = VotingClassifier(estimators=[('SVC', SVC_clf), ('DTree', DTree_clf), ('LogReg', LogReg_clf)], voting='hard')\n",
        "voting_clf.fit(X_train, y_train)\n",
        "preds = voting_clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "l_loss = log_loss(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "\n",
        "print(\"Accuracy is: \" + str(acc))\n",
        "print(\"Log Loss is: \" + str(l_loss))\n",
        "print(\"F1 Score is: \" + str(f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DVrsPrTvGI0",
        "outputId": "59f7f410-4fad-4503-ea80-52ad94073e3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.8151146180531936\n",
            "Log Loss is: 6.385716579054914\n",
            "F1 Score is: 0.035486160397444996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of evaluating a stacking ensemble for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# create the synthetic classification dataset\n",
        "X, y = make_classification(random_state=1)\n",
        "# configure the models to use in the ensemble\n",
        "models = [('knn', KNeighborsClassifier()), ('tree', DecisionTreeClassifier())]\n",
        "# configure the ensemble model\n",
        "model = StackingClassifier(models, final_estimator=LogisticRegression(), cv=3)\n",
        "# configure the resampling method\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the ensemble on the dataset using the resampling method\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report ensemble performance\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpzlhT_ltcCb",
        "outputId": "9d63c593-6589-4d20-8a24-d63153871eac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.930 (0.086)\n"
          ]
        }
      ]
    }
  ]
}