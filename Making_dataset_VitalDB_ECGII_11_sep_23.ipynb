{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq77n+4Lf0a+1KYVAQHaZJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/ARC/blob/master/Making_dataset_VitalDB_ECGII_11_sep_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/mghanem8/ECG-ST-Episode-Detection/tree/main/edb"
      ],
      "metadata": {
        "id": "to6vuzbCnhDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgYh25aEmJyA",
        "outputId": "2d768acf-1a91-4009-ec85-876c9dfc162c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vitaldb in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vitaldb) (2.31.0)\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.10/dist-packages (from vitaldb) (4.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2023.7.22)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->vitaldb) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb->vitaldb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->vitaldb) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q wfdb\n",
        "!pip install -q neurokit2\n",
        "!pip install -q biosppy\n",
        "!pip install vitaldb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import neurokit2 as nk\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import biosppy.signals.ecg as ecg\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import vitaldb\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "6thl8l2FnuNq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r_wave_amplitude(r_peak_loc):\n",
        "    if len(r_peak_loc) >= 1:\n",
        "        r_amplitude = float(r_peak_loc.values[0])\n",
        "        return r_amplitude\n",
        "    return np.nan\n",
        "\n",
        "def r_wave_duration(q_peak_loc, t_onset_loc):\n",
        "    if len(q_peak_loc) >= 1 and len(t_onset_loc) >= 1:\n",
        "        r_duration = float(q_peak_loc.index[0] - t_onset_loc.index[0])\n",
        "        return r_duration\n",
        "    return np.nan\n",
        "\n",
        "def t_wave_amplitude(t_peak_loc):\n",
        "    if len(t_peak_loc) >= 1:\n",
        "        t_amplitude = float(t_peak_loc.values[0])\n",
        "        return t_amplitude\n",
        "    return np.nan\n",
        "\n",
        "def t_wave_duration(t_offset_loc, t_onset_loc):\n",
        "    if len(t_offset_loc) >= 1 and len(t_onset_loc) >= 1:\n",
        "        t_duration = float(t_offset_loc.index[0] - t_onset_loc.index[0])\n",
        "        return t_duration\n",
        "    return np.nan\n",
        "\n",
        "def s_wave_amplitude(s_peak_loc):\n",
        "    if len(s_peak_loc) >= 1:\n",
        "        s_amplitude = float(s_peak_loc.values[0])\n",
        "        return s_amplitude\n",
        "    return np.nan\n",
        "\n",
        "def qt_interval(t_offset_loc, p_offset_loc):\n",
        "    if len(t_offset_loc) >= 1 and len(p_offset_loc) >= 1:\n",
        "        qt_interval = float(t_offset_loc.index[0] - p_offset_loc.index[0])\n",
        "        return qt_interval\n",
        "    return np.nan\n",
        "\n",
        "def heart_rate_calc(hr, idx):\n",
        "    if idx > 0:\n",
        "        return float(hr[idx])\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def j_point_calc(s_peak_loc, t_peak_loc, x, y):\n",
        "    if len(s_peak_loc) == 0 or len(t_peak_loc) == 0:\n",
        "        return np.nan, np.nan, None\n",
        "    if s_peak_loc.index[0] > t_peak_loc.index[0]:\n",
        "        return np.nan, np.nan, None\n",
        "    s_peak_ind = int(np.interp(s_peak_loc.index[0], x, np.arange(len(x))))\n",
        "    t_peak_ind = int(np.interp(t_peak_loc.index[0], x, np.arange(len(x))))\n",
        "    y_st_by_peaks = y[s_peak_ind:t_peak_ind+1]\n",
        "    x_st_by_peaks = x[s_peak_ind:t_peak_ind+1]\n",
        "    if t_peak_ind - s_peak_ind < 1:\n",
        "        return np.nan, np.nan, None\n",
        "    Fy = np.gradient(y_st_by_peaks)\n",
        "    j_point_pseudo_ind = np.abs(Fy).argmin()\n",
        "    j_point = [x_st_by_peaks[j_point_pseudo_ind], y_st_by_peaks[j_point_pseudo_ind]]\n",
        "    j_point_ind = int(np.round(np.interp(x_st_by_peaks[j_point_pseudo_ind], x, np.arange(len(x)))))\n",
        "    j_magnitude = j_point[1]\n",
        "\n",
        "    return j_point, j_magnitude, j_point_ind\n",
        "\n",
        "def st_duration_calc(t_peak_loc, j_point):\n",
        "    if len(t_peak_loc) >= 1 and isinstance(j_point, list) and len(j_point) == 2:\n",
        "        st_duration = t_peak_loc.index[0] - j_point[0]\n",
        "        return st_duration\n",
        "    return np.nan\n",
        "\n",
        "def st_slope_calc(t_onset_loc, j_point_ind, x, y):\n",
        "    if len(t_onset_loc) >= 1 and j_point_ind is not None:\n",
        "        t_onset_ind = int(np.round(np.interp(t_onset_loc.index[0], x, np.arange(len(x)))))\n",
        "\n",
        "        if t_onset_ind > j_point_ind:\n",
        "            y_st_slope_range = y[j_point_ind:t_onset_ind+1]\n",
        "            x_st_slope_range = x[j_point_ind:t_onset_ind+1]\n",
        "\n",
        "            F_st_slope = np.gradient(y_st_slope_range)\n",
        "            st_slope = np.mean(F_st_slope)\n",
        "            st_slope_bool = st_slope > 0\n",
        "            return st_slope\n",
        "    return np.nan\n",
        "\n",
        "def st_area_calc(t_offset_loc, j_point_ind, x, y,):\n",
        "    if len(t_offset_loc) >= 1 and j_point_ind is not None:\n",
        "        ind_t_offset = int(np.round(np.interp(t_offset_loc.index[0], x, np.arange(len(x)))))\n",
        "        y_st_area_range = y[j_point_ind:ind_t_offset+1]\n",
        "        x_st_area_range = x[j_point_ind:ind_t_offset+1]\n",
        "        st_area = np.trapz(y_st_area_range, x_st_area_range)\n",
        "        return st_area\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_features(beats, features,case_id):\n",
        "\n",
        "    p_onsets = features[\"ECG_P_Onsets\"]\n",
        "    r_onsets = features[\"ECG_R_Onsets\"]\n",
        "    t_onsets = features[\"ECG_T_Onsets\"]\n",
        "    p_offsets = features[\"ECG_P_Offsets\"]\n",
        "    r_offsets = features[\"ECG_R_Offsets\"]\n",
        "    t_offsets = features[\"ECG_T_Offsets\"]\n",
        "    r_peaks = features[\"ECG_R_Peaks\"]\n",
        "    t_peaks = features[\"ECG_T_Peaks\"]\n",
        "    q_peaks = features[\"ECG_Q_Peaks\"]\n",
        "    s_peaks = features[\"ECG_S_Peaks\"]\n",
        "    p_peaks = features[\"ECG_P_Peaks\"]\n",
        "    heart_rate = features[\"ECG_Rate\"]\n",
        "    cycles=0\n",
        "\n",
        "    record_dataset = pd.DataFrame(columns=['Case_ID','Cycle','R_wave_amplitude', 'R_wave_duration', 'T_wave_amplitude', 'T_wave_duration', 'S_wave_amplitude', 'QT_interval', 'Heart_rate','J_point_amplitude', 'ST_duration', 'ST_area', 'ST_slope'])\n",
        "\n",
        "    for i in tqdm(range(1, len(beats)+1)):\n",
        "        beat = beats[str(i)]\n",
        "        beat_signal = beat['Signal']\n",
        "        time = beat_signal.index\n",
        "        voltage = beat_signal.values\n",
        "        beat_idx = beat['Index'].values\n",
        "        min_idx, max_idx = beat_idx[0], beat_idx[-1]\n",
        "\n",
        "        s_peak_loc = beat_signal.iloc[np.argwhere(s_peaks[min_idx:max_idx].values == 1).flatten()]\n",
        "        r_onset_loc = beat_signal.iloc[np.argwhere(r_onsets[min_idx:max_idx].values == 1).flatten()]\n",
        "        t_onset_loc = beat_signal.iloc[np.argwhere(t_onsets[min_idx:max_idx].values == 1).flatten()]\n",
        "        p_offset_loc = beat_signal.iloc[np.argwhere(p_offsets[min_idx:max_idx].values == 1).flatten()]\n",
        "        r_offset_loc = beat_signal.iloc[np.argwhere(r_offsets[min_idx:max_idx].values == 1).flatten()]\n",
        "        t_offset_loc = beat_signal.iloc[np.argwhere(t_offsets[min_idx:max_idx].values == 1).flatten()]\n",
        "        r_peak_loc = beat_signal.iloc[np.argwhere(r_peaks[min_idx:max_idx].values == 1).flatten()]\n",
        "        t_peak_loc = beat_signal.iloc[np.argwhere(t_peaks[min_idx:max_idx].values == 1).flatten()]\n",
        "        q_peak_loc = beat_signal.iloc[np.argwhere(q_peaks[min_idx:max_idx].values == 1).flatten()]\n",
        "\n",
        "\n",
        "        r_amplitude = r_wave_amplitude(r_peak_loc)\n",
        "        r_duration = r_wave_duration(q_peak_loc, r_onset_loc)\n",
        "        t_amplitude = t_wave_amplitude(t_peak_loc)\n",
        "        t_duration = t_wave_duration(t_offset_loc, t_onset_loc)\n",
        "        s_amplitude = s_wave_amplitude(s_peak_loc)\n",
        "        qt_int = qt_interval(t_offset_loc, p_offset_loc)\n",
        "        hr = heart_rate_calc(heart_rate, (min_idx + max_idx) // 2)\n",
        "        j_point, j_magnitude, j_point_ind = j_point_calc(s_peak_loc, t_peak_loc, time, voltage)\n",
        "        st_duration = st_duration_calc(t_peak_loc, j_point)\n",
        "        st_slope = st_slope_calc(t_onset_loc, j_point_ind, time, voltage)\n",
        "        st_area = st_area_calc(t_offset_loc, j_point_ind, time, voltage)\n",
        "        cycles+=1\n",
        "\n",
        "        feature_row = {\n",
        "            'Case_ID': case_id,\n",
        "            'Cycle': cycles,\n",
        "            'R_wave_amplitude': r_amplitude,\n",
        "            'R_wave_duration': r_duration,\n",
        "            'T_wave_amplitude': t_amplitude,\n",
        "            'T_wave_duration': t_duration,\n",
        "            'S_wave_amplitude': s_amplitude,\n",
        "            'QT_interval': qt_int,\n",
        "            'Heart_rate': hr,\n",
        "            'J_point_amplitude': j_magnitude,\n",
        "            'ST_duration': st_duration,\n",
        "            'ST_area': st_area,\n",
        "            'ST_slope': st_slope\n",
        "        }\n",
        "\n",
        "        feature_row = pd.DataFrame([feature_row])\n",
        "        record_dataset = pd.concat([record_dataset, feature_row], ignore_index=True)\n",
        "\n",
        "    return record_dataset"
      ],
      "metadata": {
        "id": "E9PJ-umwpKuP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")\n",
        "df_trks = pd.read_csv('https://api.vitaldb.net/trks')\n",
        "df_labs = pd.read_csv('https://api.vitaldb.net/labs')"
      ],
      "metadata": {
        "id": "Cm9ZgS-Sn2LR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inclusion / exclusion criteria\n",
        "caseids = list(\n",
        "    set(df_trks.loc[df_trks['tname'] == 'SNUADC/ECG_II', 'caseid'])\n",
        ")\n",
        "\n",
        "print('Total {} cases found'.format(len(caseids)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMWvg-qon5a3",
        "outputId": "35dea70a-f791-45c9-c63a-c3bfd214f3d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 6355 cases found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [15, 5]\n",
        "plt.rcParams['font.size']= 14\n",
        "\n",
        "def nrml_plt(sig):\n",
        "  plt.figure(figsize=(20,15))\n",
        "  plt.subplot(211)\n",
        "  plt.plot(sig, color='coral')\n",
        "  plt.grid(True)\n",
        "  plt.ylim([-3, 3])\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UiIolxzqn8LN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srate = 100\n",
        "\n",
        "#case_complete_list = list(dataset_main[\"Case_ID\"].unique())\n",
        "\n",
        "dataset_main = pd.DataFrame(columns=['Case_ID','Cycle','R_wave_amplitude', 'R_wave_duration', 'T_wave_amplitude', 'T_wave_duration', 'S_wave_amplitude', 'QT_interval', 'Heart_rate','J_point_amplitude', 'ST_duration', 'ST_area', 'ST_slope'])\n",
        "\n",
        "\n",
        "for caseid in tqdm(caseids):\n",
        "\n",
        "  vals = vitaldb.load_case(caseid, ['SNUADC/ECG_II'], 1 / srate)\n",
        "  initial_signal = vals[:,0]\n",
        "\n",
        "\n",
        "  print(\"Process Started For \", caseid)\n",
        "  print(\"Signal Cleaning Started\")\n",
        "\n",
        "  op_st = df_cases[(df_cases['caseid'] == caseid)]['opstart'].values[0]\n",
        "  op_end = df_cases[(df_cases['caseid'] == caseid)]['opend'].values[0]\n",
        "\n",
        "\n",
        "  count = 0\n",
        "  seconds = 0\n",
        "\n",
        "  for i in initial_signal:\n",
        "    count+=1\n",
        "    if count*(1/500)>= op_st:\n",
        "      break\n",
        "\n",
        "\n",
        "  count2 = 0\n",
        "  seconds = 0\n",
        "  for i in initial_signal:\n",
        "    count2+=1\n",
        "    if count2*(1/500) >= op_end:\n",
        "      break\n",
        "\n",
        "  initial_signal = vals[:,0][count:count2]\n",
        "  initial_signal = initial_signal[np.logical_not(np.isnan(initial_signal))]\n",
        "\n",
        "\n",
        "  initial_signal = initial_signal[(initial_signal>= -.25) & (initial_signal<=.25)]\n",
        "  signal_clean = nk.ecg_clean(initial_signal, sampling_rate=srate)\n",
        "  print(\"Signal Cleaning Complete......\")\n",
        "\n",
        "  print(\"Features and Beats extracting Started......\")\n",
        "  features, _ = nk.ecg_process(signal_clean, sampling_rate=srate)\n",
        "  beats = nk.ecg_segment(signal_clean, sampling_rate=srate)\n",
        "  print(\"Features and Beats extracting Completed......\")\n",
        "\n",
        "\n",
        "  print(\"Makind Dataset\")\n",
        "  data = extract_features(beats, features,caseid)\n",
        "  print(\"Dataset Complete\")\n",
        "  dataset_main = pd.concat([dataset_main, data], axis=0)\n",
        "  print(\"Dataset Concatination Complete\")\n",
        "  print(\"Process Complete for Case ID: \", caseid)\n",
        "  print(\"............................................................\")\n",
        "  print(\"............................................................\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54K-LLV0oShf",
        "outputId": "6f6923af-3283-4825-8fe3-622764a67b0d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process Started For  2\n",
            "Signal Cleaning Started\n",
            "Signal Cleaning Complete......\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YAbKHR5wPIzz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}