{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/ARC/blob/master/TJ_DS_Healthcare_experiment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wBkhg5BGQ-x3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMhcRSElRAQ9",
        "outputId": "94ae813b-fa02-44c8-9d11-9372772c08d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx4_EcpnY3Vc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "data= pd.read_excel('/content/drive/MyDrive/Tanjila_mam/DS-Healthcare_version_2.xlsx')\n",
        "result = {}\n",
        "target = 'Type'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kINGzC62CKQc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "\n",
        "data[target]=encoder.fit_transform(data[target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_kOuErJ9WJt"
      },
      "outputs": [],
      "source": [
        "X= data.loc[:,data.columns != target]\n",
        "y = data[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntfY_FwPwUvB"
      },
      "outputs": [],
      "source": [
        "def fun_split(X,Y,test_size,feature):\n",
        "\n",
        "    f=Y.value_counts()\n",
        "    rows=X.shape[0]\n",
        "    talika=[]\n",
        "    count=0\n",
        "    for i in f:\n",
        "        talika.append(i)\n",
        "    train_size=1-test_size\n",
        "    start=0\n",
        "\n",
        "    switch=False\n",
        "\n",
        "    for i in talika :\n",
        "\n",
        "        train=start+int(i*train_size)\n",
        "        f= X[feature][train]\n",
        "        count1=0\n",
        "        count2=0\n",
        "        index1=train\n",
        "        index2=train+1\n",
        "        end=start+i-1\n",
        "        \n",
        "        while X[feature][index1]==f:\n",
        "            if index1<start:\n",
        "                break\n",
        "            index1-=1\n",
        "            count1+=1\n",
        "            \n",
        "            \n",
        "        while X[feature][index2]==f:\n",
        "            if index2>end:\n",
        "                break\n",
        "            index2+=1\n",
        "            count2+=1\n",
        "\n",
        "        if count1>=count2:\n",
        "            train+=count2\n",
        "        else:\n",
        "            train-=count1\n",
        "        \n",
        "        \n",
        "        if switch == False:\n",
        "            X_train= X[start:train+1]\n",
        "            X_test= X[train+1:end]\n",
        "            Y_train = Y[start:train+1]\n",
        "            Y_test = Y[train+1:end]\n",
        "            switch=True\n",
        "\n",
        "        else:\n",
        "            X_train=pd.concat([X_train, X[start:train+1]], ignore_index=True)\n",
        "            X_test=pd.concat([X_test, X[train+1:end+1]], ignore_index=True)\n",
        "            Y_train=pd.concat([Y_train, Y[start:train+1]], ignore_index=True)\n",
        "            Y_test=pd.concat([Y_test, Y[train+1:end+1]], ignore_index=True)\n",
        "\n",
        "        start=start+i\n",
        "\n",
        "    print('Train Percentage:',X_train.shape[0]/rows)\n",
        "\n",
        "    return X_train,X_test,Y_train,Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGDUc9EbgWz1"
      },
      "outputs": [],
      "source": [
        " X_train, X_test, y_train, y_test = fun_split(X,y, test_size=0.2, feature= 'Subject')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KhmZN1XXZQP"
      },
      "outputs": [],
      "source": [
        "\"\"\"#testing if there is any mixing with training subject and testing subject\n",
        "from tqdm.notebook import tqdm\n",
        "train = list(X_train[\"Subject\"])\n",
        "test = list(X_test[\"Subject\"])\n",
        "\n",
        "dup = []\n",
        "\n",
        "for i in tqdm(test):\n",
        "  if i in train:\n",
        "    dup.append(i)\n",
        "print(dup)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4TP6fPUgWz3"
      },
      "outputs": [],
      "source": [
        "X_train= X_train.loc[:,X_train.columns != 'Subject']\n",
        "X_train= X_train.loc[:,X_train.columns != 'Time']\n",
        "X_train= X_train.loc[:,X_train.columns != 'Cycle']\n",
        "\n",
        "X_test= X_test.loc[:,X_test.columns != 'Subject']\n",
        "X_test= X_test.loc[:,X_test.columns != 'Time']\n",
        "X_test= X_test.loc[:,X_test.columns != 'Cycle']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhZIhJsPXXw9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU3-SHeM7WkG"
      },
      "source": [
        "#Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeNjHkzK7fm6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_defult = AdaBoostClassifier()\n",
        "\n",
        "ada_defult.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ada_defult.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(ada_defult,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZwSx5ud7bvZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "N=10\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  classifier = AdaBoostClassifier(n_estimators=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "#plot the relationship between K and the testing accuracy\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgcrinRigWz6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_best_estimator = AdaBoostClassifier(n_estimators=best_estimator,random_state=0)\n",
        "ada_best_estimator.fit(X_train, y_train)\n",
        "y_pred = ada_best_estimator.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(ada_best_estimator,1,'AdaBoostClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZd5YujH8cwq"
      },
      "source": [
        "#GradientBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqaUXUXH8cdg"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "gradBoost_default = GradientBoostingClassifier(random_state=0)\n",
        "gradBoost_default.fit(X_train, y_train)\n",
        "y_pred = gradBoost_default.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(gradBoost_default,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c56LI1DZ8gLx"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=63\n",
        "k_range = range (58,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  classifier = GradientBoostingClassifier(n_estimators=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlZae1wN8vl6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=4\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  classifier = GradientBoostingClassifier(max_depth=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best Depth:\")\n",
        "best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_depth)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoooaxGn868r"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradBoost_estimator = GradientBoostingClassifier(n_estimators=best_estimator,random_state=0)\n",
        "gradBoost_estimator.fit(X_train, y_train)\n",
        "y_pred = gradBoost_estimator.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(gradBoost_estimator,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ2xJ6nf89_x"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradBoost_depth = GradientBoostingClassifier(max_depth=best_depth,random_state=0)\n",
        "gradBoost_depth.fit(X_train, y_train)\n",
        "y_pred = gradBoost_depth.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(gradBoost_depth,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgfw0pHJ8_o7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradBoost_all = GradientBoostingClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n",
        "gradBoost_all.fit(X_train, y_train)\n",
        "y_pred = gradBoost_all.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(gradBoost_all,2,'GradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DzjR9PO7lx5"
      },
      "source": [
        "#RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzpKxk9jgWz5"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_default = RandomForestClassifier(random_state=0)\n",
        "rf_default.fit(X_train, y_train)\n",
        "y_pred=rf_default.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_default,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQt_u2H--3nY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=5\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  classifier = RandomForestClassifier(n_estimators=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlDpXMm8-5FU"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=13\n",
        "k_range = range (7,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  classifier = RandomForestClassifier(max_depth=k,random_state=0)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best Depth:\")\n",
        "best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8iHZZg1-45W"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_estimator = RandomForestClassifier(n_estimators=best_estimator,random_state=0)\n",
        "rf_estimator.fit(X_train, y_train)\n",
        "y_pred=rf_estimator.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_estimator,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YPFCBVg_BE3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_depth = RandomForestClassifier(max_depth=best_depth,random_state=0)\n",
        "rf_depth.fit(X_train, y_train)\n",
        "y_pred=rf_depth.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_depth,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsXWn29V_EjK"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_all = RandomForestClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n",
        "rf_all.fit(X_train, y_train)\n",
        "y_pred=rf_all.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(rf_all,3,'RandomForestClassifier')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI7bu8gS-yZP"
      },
      "source": [
        "#XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcg3IpeSqF7h"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTg4ZVi__Myn"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "xgb_deafult = xgb.XGBClassifier(random_state=0)\n",
        "xgb_deafult.fit(X_train.values,y_train.values)\n",
        "y_pred = xgb_deafult.predict(X_test.values)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_deafult,4,'xgboost')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phXUe_iVp2QY"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=5\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  xgb_classifier = xgb.XGBClassifier(n_estimators=k,random_state=0)\n",
        "  xgb_classifier.fit(X_train.values, y_train.values)\n",
        "  y_pred=xgb_classifier.predict(X_test.values)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best n_estimators:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6lTOBtijjuI"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=5\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  xgb_classifier = xgb.XGBClassifier(max_depth=k,random_state=0)\n",
        "  xgb_classifier.fit(X_train.values, y_train.values)\n",
        "  y_pred=xgb_classifier.predict(X_test.values)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best depth:\")\n",
        "best_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgVwPCMV_YVe"
      },
      "outputs": [],
      "source": [
        "\n",
        "import xgboost as xgb\n",
        "xgb_depth = xgb.XGBClassifier(max_depth=best_depth,random_state=0)\n",
        "xgb_depth.fit(X_train.values,y_train.values)\n",
        "y_pred = xgb_depth.predict(X_test.values)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_depth,4,'xgboost')]=accuracy_score(y_test, y_pred)\n",
        "print(xgb_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRlT0_X9_a7d"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "xgb_estimator = xgb.XGBClassifier(n_estimators=best_estimator,random_state=0)\n",
        "xgb_estimator.fit(X_train.values,y_train.values)\n",
        "y_pred = xgb_estimator.predict(X_test.values)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_estimator,4,'xgboost')]=accuracy_score(y_test, y_pred)\n",
        "print(xgb_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujcK6z9K_dfd"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "xgb_all = xgb.XGBClassifier(n_estimators=best_estimator,max_depth=best_depth,random_state=0)\n",
        "xgb_all.fit(X_train.values,y_train.values)\n",
        "y_pred = xgb_all.predict(X_test.values)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(xgb_all,4,'xgboost')]=accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Histogram-Based Gradient Boosting"
      ],
      "metadata": {
        "id": "7dknY9xVr3iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hisgradBoost_default = HistGradientBoostingClassifier(random_state=0)\n",
        "hisgradBoost_default.fit(X_train, y_train)\n",
        "y_pred = hisgradBoost_default.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(hisgradBoost_default,5,'HistGradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "2qFWWrUvr2uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=10\n",
        "k_range = range (5,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  hisgradBoost_cls = HistGradientBoostingClassifier(max_iter=k,random_state=0)\n",
        "  hisgradBoost_cls.fit(X_train, y_train)\n",
        "  y_pred=hisgradBoost_cls.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best max_iter:\")\n",
        "best_estimator=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best_estimator)"
      ],
      "metadata": {
        "id": "6ucWtYhAr2qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=5\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in tqdm(k_range):\n",
        "  hisgradBoost_cls = HistGradientBoostingClassifier(max_depth=k,random_state=0)\n",
        "  hisgradBoost_cls.fit(X_train, y_train)\n",
        "  y_pred=hisgradBoost_cls.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "print(\"The best max_depth:\")\n",
        "max_depth=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(max_depth)"
      ],
      "metadata": {
        "id": "VpTzSO-zr2l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "hisgradBoost_max_iter = HistGradientBoostingClassifier(max_iter=best_estimator,random_state=0)\n",
        "hisgradBoost_max_iter.fit(X_train, y_train)\n",
        "y_pred = hisgradBoost_max_iter.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(hisgradBoost_max_iter,5,'HistGradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "VLI6LODmr2aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "hisgradBoost_max_depth = HistGradientBoostingClassifier(max_depth=max_depth,random_state=0)\n",
        "hisgradBoost_max_depth.fit(X_train, y_train)\n",
        "y_pred = hisgradBoost_max_depth.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(hisgradBoost_max_depth,5,'HistGradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cx6zu8oms8NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "hisgradBoost_all = HistGradientBoostingClassifier(max_iter=best_estimator,max_depth=max_depth,random_state=0)\n",
        "hisgradBoost_all.fit(X_train, y_train)\n",
        "y_pred = hisgradBoost_all.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))\n",
        "result[(hisgradBoost_all,5,'HistGradientBoostingClassifier')]=accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Hiv4rn2Os7kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rh4SyQSOvfhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5zAjrW3veWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tUszxPcB81P"
      },
      "source": [
        "#Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK1Asgq6B8VT"
      },
      "outputs": [],
      "source": [
        "models=[]\n",
        "\n",
        "for i in result:\n",
        "  models.append(i[0])\n",
        "  print(i[0],i[1],\" : \",result[i])\n",
        "  print(\"---------------------------------------------------------------\")\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElQVIr1fCfcX"
      },
      "source": [
        "#Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajtf_zSrCe4z"
      },
      "outputs": [],
      "source": [
        "\"\"\"from sklearn.model_selection import cross_val_score\n",
        "\n",
        "k=5\n",
        "for i in result:\n",
        "  print(i[0],\" -> Accuracy: \",result[i])\n",
        "  l=list(cross_val_score(i[0],X_new, y_new,cv=k))\n",
        "  avg=sum(l)/k\n",
        "  print(i[0],\" -> AVG Accurecy After CV: \"+str(avg)+ \" (For \"+str(k)+\" Fold)\")\n",
        "  print(\"--------------------------------------------------------------------------\")\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He6Hv001Crn8"
      },
      "source": [
        "#SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRAdOJ6CCs63"
      },
      "outputs": [],
      "source": [
        "def SHAP_EXP(model,graph_feat):\n",
        "  print(\"Models: \",model)\n",
        "\n",
        "  explainer = shap.Explainer(model.predict, X_test)\n",
        "\n",
        "  shap_values1 = explainer(X_test)\n",
        "  features_names=list_of_feat\n",
        "\n",
        "  if 'Subjects' in features_names:\n",
        "    features_names.pop(0)\n",
        "\n",
        "\n",
        "  shap.plots.bar(shap_values1,max_display=graph_feat[\"max_display\"])\n",
        "\n",
        "  print(\"---------------------\")\n",
        "\n",
        "  shap.summary_plot(shap_values1,max_display=graph_feat[\"max_display\"],feature_names=features_names)\n",
        "\n",
        "  print(\"---------------------\")\n",
        "\n",
        "  print(\"Local Explaination\")\n",
        "  shap.plots.waterfall(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])\n",
        "\n",
        "\n",
        "  print(\"---------------------\")\n",
        "\n",
        "  shap.plots.bar(shap_values1[graph_feat[\"shap_values Index\"]],max_display=graph_feat[\"max_display\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6HqCS73C07o"
      },
      "outputs": [],
      "source": [
        "graph_feat={\n",
        "    \"max_display\":20,\n",
        "    \"shap_values Index\":2\n",
        "}\n",
        "\n",
        "for i in range(len(new_keys_7)):\n",
        "  if new_keys_7[i].value ==True:\n",
        "    SHAP_EXP(models[i],graph_feat)\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "    print(\"---------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMT13jBODAz6"
      },
      "source": [
        "#Lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouEfp1YgDCbG"
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKE7mXC0DD-_"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "from lime import lime_tabular\n",
        "\n",
        "def LIME_EXP(model,row):\n",
        "\n",
        "    if str(model)[:3] == \"XGB\":\n",
        "\n",
        "      explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "        X_train.values,\n",
        "        feature_names=list(list(X_new.columns)),                                         \n",
        "        class_names=['Reading', 'Resting', 'Walking', 'Working']\n",
        "        )\n",
        "      \n",
        "      exp = explainer.explain_instance(X_test.iloc[row, :].values,\n",
        "                                 model.predict_proba,\n",
        "                                 num_features=6,\n",
        "                                 top_labels=2)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "      explainer = lime_tabular.LimeTabularExplainer(\n",
        "        training_data=np.array(X_train),\n",
        "        feature_names=list(X_new.columns),\n",
        "        class_names=['Reading', 'Resting', 'Walking', 'Working'],\n",
        "        mode='classification'\n",
        "        )\n",
        "\n",
        "      exp = explainer.explain_instance(X_test.iloc[row],\n",
        "                                      model.predict_proba,               \n",
        "                                      num_features=6,\n",
        "                                      top_labels=4)\n",
        "    \n",
        "\n",
        "\n",
        "    exp.show_in_notebook(show_table=True, show_all=True)\n",
        "\n",
        "\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    with plt.style.context(\"ggplot\"):\n",
        "        exp.as_pyplot_figure()\n",
        "\n",
        "\n",
        "    from IPython.display import HTML\n",
        "    html_data = exp.as_html()\n",
        "    HTML(data=html_data)\n",
        "\n",
        "    exp.save_to_file(str(model)+\".html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL82BQW-DDzI"
      },
      "outputs": [],
      "source": [
        "row = int(input(\"Enter the index of row to explain: \"))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PGbAZQiDDjM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH_rkXrwDDez"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}