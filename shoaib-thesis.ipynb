{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install pandas openpyxl\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_excel('/kaggle/input/ecg-ds-health-care/DS-Healthcare.xlsx',header = 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnew_column_names = data.iloc[0]  \ndata.columns = new_column_names  \ndata = data[1:]  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Type.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Type'] = data['Type'].map({'arrhythmic': 'unhealthy', 'ischemic': 'unhealthy', 'healthy': 'healthy'})\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Type\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming your DataFrame is named 'data'\nnull_count = data.isnull().sum()\n\n# Display the count of null values for each column\nprint(null_count)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_null_count = null_count.sum()\nprint(f'Total number of null values: {total_null_count}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U imbalanced-learn\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data= data.drop('Subject', axis=1)\ndata= data.drop('Cycle', axis=1)      #added by Rafsan\ndata= data.drop('Time', axis=1)      # added by Rafsan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Assuming your DataFrame is named 'data'\nlabel_encoder = LabelEncoder()\n\n# Apply label encoding to the 'Type' column\ndata['Type'] = label_encoder.fit_transform(data['Type'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Type.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"# New Code Added","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data= data.apply(pd.to_numeric, errors='coerce') #added by rafsan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.loc[:,data.columns!='Type']\ny = data['Type']","metadata":{"execution":{"iopub.status.busy":"2024-01-01T06:14:51.810728Z","iopub.execute_input":"2024-01-01T06:14:51.811605Z","iopub.status.idle":"2024-01-01T06:14:51.841777Z","shell.execute_reply.started":"2024-01-01T06:14:51.811571Z","shell.execute_reply":"2024-01-01T06:14:51.840832Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T06:14:52.981396Z","iopub.execute_input":"2024-01-01T06:14:52.981892Z","iopub.status.idle":"2024-01-01T06:14:53.101602Z","shell.execute_reply.started":"2024-01-01T06:14:52.981858Z","shell.execute_reply":"2024-01-01T06:14:53.100501Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"X_train = tf.convert_to_tensor(X_train.values.astype(np.float64))\nX_test = tf.convert_to_tensor(X_test.values.astype(np.float64))\ny_train = tf.convert_to_tensor(y_train.values.astype(np.float64))\ny_test = tf.convert_to_tensor(y_test.values.astype(np.float64))","metadata":{"execution":{"iopub.status.busy":"2024-01-01T06:14:54.245076Z","iopub.execute_input":"2024-01-01T06:14:54.245442Z","iopub.status.idle":"2024-01-01T06:14:54.380387Z","shell.execute_reply.started":"2024-01-01T06:14:54.245414Z","shell.execute_reply":"2024-01-01T06:14:54.379466Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-01T06:14:57.178820Z","iopub.execute_input":"2024-01-01T06:14:57.179669Z","iopub.status.idle":"2024-01-01T06:14:57.185786Z","shell.execute_reply.started":"2024-01-01T06:14:57.179625Z","shell.execute_reply":"2024-01-01T06:14:57.184851Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"(TensorShape([838859, 9]), TensorShape([838859]))"},"metadata":{}}]},{"cell_type":"markdown","source":"### LSTM","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Conv2D, Flatten, Dense\n# Define the LSTM model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.LSTM(64, input_shape=(X_train.shape[1], 1)))\n#model.add(Flatten())\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\n\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RNN","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense\n\nmodel = Sequential()\nmodel.add(SimpleRNN(50, input_shape=(X_train.shape[1],1)))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Train the model (Assuming X_train and y_train are your training data)\nmodel.fit(X_train, y_train, epochs=5, batch_size=32)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN from (previous notebook from shoaib)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"________________________________________________________________________________________________________________________\n________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nimport numpy as np\n\n# Assuming your DataFrame is named 'data'\n# Assuming 'Type' is the column with the class labels\n\n# Drop non-numeric columns or encode them if needed\ndata_numeric = data.select_dtypes(include=['number'])\n\n# Create feature matrix X and target variable y\nX = data_numeric.drop('Type', axis=1).values\ny = data_numeric['Type'].values\n\n# Convert labels to numerical values using LabelEncoder\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Convert numerical labels to PyTorch tensors\nX_tensor = torch.tensor(X, dtype=torch.float32)\ny_tensor = torch.tensor(y_encoded, dtype=torch.long)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n\n# Print input size\nprint(\"Input size:\", X_train.size())\n\n# Define the MLP model in PyTorch\nclass MLPModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(MLPModel, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n\n# Instantiate the model\ninput_size = X_train.size(1)  # Adjusted input size\nhidden_size = 64  # You can adjust the hidden size as needed\nnum_classes = len(label_encoder.classes_)\nmodel = MLPModel(input_size, hidden_size, num_classes)\n\n# Print model architecture\nprint(model)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training the model\nnum_epochs = 500\nfor epoch in range(num_epochs):\n    model.train()\n    outputs = model(X_train)\n    loss = criterion(outputs, y_train)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Evaluation on the test set\nmodel.eval()\nwith torch.no_grad():\n    y_pred = model(X_test)\n    _, y_pred_labels = torch.max(y_pred, 1)\n    y_true_labels = y_test\n\n# Convert predictions back to original labels\ny_pred_original = label_encoder.inverse_transform(y_pred_labels.numpy())\ny_true_original = label_encoder.inverse_transform(y_true_labels.numpy())\n\n# Calculate accuracy and other metrics\naccuracy = accuracy_score(y_true_original, y_pred_original)\nreport = classification_report(y_true_original, y_pred_original)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", report)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time \nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\nfrom keras.utils import to_categorical\n\n# Assuming your DataFrame is named 'data'\n# Assuming 'Type' is the column with the class labels\n\n# Drop non-numeric columns or encode them if needed\ndata_numeric = data.select_dtypes(include=['number'])\n\n# Create feature matrix X and target variable y\nX = data_numeric.drop('Type', axis=1)\ny = data_numeric['Type']\n\n# Convert labels to numerical values using LabelEncoder\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Convert numerical labels to one-hot encoding\ny_one_hot = to_categorical(y_encoded)\n\n# Set the maximum window size based on available data\nmax_window_size = len(X)\n\n# Decrease the window size until it fits the data\ninput_window_size = max_window_size\nwhile input_window_size > 1:\n    X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n    \n    X_train_reshaped = np.array([X_train.iloc[i:i+input_window_size].values for i in range(len(X_train)-input_window_size+1)])\n    X_test_reshaped = np.array([X_test.iloc[i:i+input_window_size].values for i in range(len(X_test)-input_window_size+1)])\n    \n    if X_train_reshaped.size > 0 and X_test_reshaped.size > 0:\n        break\n    \n    input_window_size -= 1\nprint(\"Printed\")\n\n# Check if the adjusted window size is suitable\nif input_window_size <= 1:\n    raise ValueError(\"No suitable window size found. Adjust the window size or provide more data.\")\n\n# Print the adjusted window size\nprint(f\"Adjusted input window size: {input_window_size}\")\n\n# Reshape the input data to have one channel\nX_train_reshaped = X_train_reshaped.reshape((X_train_reshaped.shape[0], X_train_reshaped.shape[1], 1))\nX_test_reshaped = X_test_reshaped.reshape((X_test_reshaped.shape[0], X_test_reshaped.shape[1], 1))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(label_encoder.classes_), activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nimport time\n\n# ... (your existing code)\n\n# Record the start time\nstart_time = time.time()\n\n# Train the model\nprint(\"Printed\")\nmodel.fit(X_train_reshaped, y_train, epochs=2, batch_size=32, validation_split=0.2)\nend_time = time.time()\n\n# Calculate the time taken\ntraining_time = end_time - start_time\nprint(f\"Training time: {training_time} seconds\")\n\n# Evaluate the model on the test set\ny_pred = model.predict(X_test_reshaped)\ny_pred_labels = np.argmax(y_pred, axis=1)\ny_true_labels = np.argmax(y_test, axis=1)\n\n# Convert predictions back to original labels\ny_pred_original = label_encoder.inverse_transform(y_pred_labels)\ny_true_original = label_encoder.inverse_transform(y_true_labels)\n\n# Calculate accuracy and other metrics\naccuracy = accuracy_score(y_true_original, y_pred_original)\nreport = classification_report(y_true_original, y_pred_original)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}